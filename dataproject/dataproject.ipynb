{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOUR PROJECT TITLE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, I will be using two data sets that are relevant to agriculture and weather in the United States, specifically North Dakota, being one of the biggest wheat producing states in the US. The first data set contains information on yearly corn yield per acre, from around 1900 to 2022. This data is from USDA National Agricultural Statistics Service (NASS). The second data set contains yearly average temperature, precipitation, and the date of the first freeze, from a central weather station in North Dakota, with data ranging from a similar interval as the agricultural data. This data is sourced from the National Oceanic and Atmospheric Administration (NOAA). By combining these data sets, the hope is to investigate the relationship between weather patterns and corn production in the North Dakota over the past century."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and set magics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# autoreload modules when code is run\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# user written modules\n",
    "import dataproject\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and clean data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, let's read the first data set on wheat yield and inspect it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Program  Year Period  Week Ending Geo Level         State  State ANSI  \\\n",
      "0  SURVEY  2022   YEAR          NaN     STATE  NORTH DAKOTA          38   \n",
      "1  SURVEY  2021   YEAR          NaN     STATE  NORTH DAKOTA          38   \n",
      "2  SURVEY  2020   YEAR          NaN     STATE  NORTH DAKOTA          38   \n",
      "3  SURVEY  2019   YEAR          NaN     STATE  NORTH DAKOTA          38   \n",
      "4  SURVEY  2018   YEAR          NaN     STATE  NORTH DAKOTA          38   \n",
      "\n",
      "   Ag District  Ag District Code  County  ...  Zip Code  Region  \\\n",
      "0          NaN               NaN     NaN  ...       NaN     NaN   \n",
      "1          NaN               NaN     NaN  ...       NaN     NaN   \n",
      "2          NaN               NaN     NaN  ...       NaN     NaN   \n",
      "3          NaN               NaN     NaN  ...       NaN     NaN   \n",
      "4          NaN               NaN     NaN  ...       NaN     NaN   \n",
      "\n",
      "   watershed_code  Watershed  Commodity                             Data Item  \\\n",
      "0               0        NaN      WHEAT  WHEAT - YIELD, MEASURED IN BU / ACRE   \n",
      "1               0        NaN      WHEAT  WHEAT - YIELD, MEASURED IN BU / ACRE   \n",
      "2               0        NaN      WHEAT  WHEAT - YIELD, MEASURED IN BU / ACRE   \n",
      "3               0        NaN      WHEAT  WHEAT - YIELD, MEASURED IN BU / ACRE   \n",
      "4               0        NaN      WHEAT  WHEAT - YIELD, MEASURED IN BU / ACRE   \n",
      "\n",
      "  Domain Domain Category Value  CV (%)  \n",
      "0  TOTAL   NOT SPECIFIED  48.9     NaN  \n",
      "1  TOTAL   NOT SPECIFIED  32.2     NaN  \n",
      "2  TOTAL   NOT SPECIFIED  47.6     NaN  \n",
      "3  TOTAL   NOT SPECIFIED  48.4     NaN  \n",
      "4  TOTAL   NOT SPECIFIED  47.6     NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "NDyield = pd.read_csv('ND_yield.csv')\n",
    "\n",
    "print(NDyield.head())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, we have a lot of unnecessary information, that should be dropped for simplicity and to make the data set easier to manage. Let us start by making the data set narrower by dropping everything but the year and the average yield per acre (Most other variables have the same value in each row anyways, since all the data is from North Dakota)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year  Value\n",
      "0  2022   48.9\n",
      "1  2021   32.2\n",
      "2  2020   47.6\n",
      "3  2019   48.4\n",
      "4  2018   47.6\n"
     ]
    }
   ],
   "source": [
    "drop_variables_yield = ['Program', 'Period', 'Week Ending','Geo Level','State','State ANSI','Ag District','Ag District Code', 'County', 'County ANSI', 'Zip Code', 'Region', 'watershed_code', 'Watershed','Commodity','Data Item', 'Domain', 'Domain Category', 'CV (%)']\n",
    "\n",
    "NDyield = NDyield.drop(columns = drop_variables_yield)\n",
    "\n",
    "print(NDyield.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are left with the information relevant to this project, let's continue by importing the weather data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       STATION              NAME  DATE  FZF0   PRCP  TAVG\n",
      "0  USC00325710  MC CLUSKY, ND US  1917   NaN    NaN   NaN\n",
      "1  USC00325710  MC CLUSKY, ND US  1919   NaN  13.26   NaN\n",
      "2  USC00325710  MC CLUSKY, ND US  1920   NaN  14.22   NaN\n",
      "3  USC00325710  MC CLUSKY, ND US  1921   NaN  20.16   NaN\n",
      "4  USC00325710  MC CLUSKY, ND US  1923  29.0    NaN  40.9\n"
     ]
    }
   ],
   "source": [
    "NDweather = pd.read_csv('ND_weather.csv')\n",
    "\n",
    "print(NDweather.head(5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we have some variables that can be dropped, namely 'NAME' and 'STATION', that are the same for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    DATE  FZF0   PRCP  TAVG\n",
      "0   1917   NaN    NaN   NaN\n",
      "1   1919   NaN  13.26   NaN\n",
      "2   1920   NaN  14.22   NaN\n",
      "3   1921   NaN  20.16   NaN\n",
      "4   1923  29.0    NaN  40.9\n",
      "5   1924  32.0    NaN  37.8\n",
      "6   1925  32.0    NaN  38.2\n",
      "7   1926  31.0    NaN  38.9\n",
      "8   1927  27.0    NaN  36.8\n",
      "9   1928  30.0    NaN  39.9\n",
      "10  1929  30.0    NaN  36.4\n",
      "11  1930   NaN    NaN   NaN\n",
      "12  1931  32.0    NaN  44.5\n",
      "13  1932  32.0    NaN  39.8\n",
      "14  1933  32.0  15.63  40.5\n",
      "15  1934  31.0  10.31  42.7\n",
      "16  1935  32.0  21.88  39.3\n",
      "17  1936  30.0   8.81  38.1\n",
      "18  1937  32.0  19.56  38.4\n",
      "19  1938  31.0  15.62  41.7\n"
     ]
    }
   ],
   "source": [
    "drop_variables_weather = ['STATION', 'NAME']\n",
    "NDweather = NDweather.drop(columns=drop_variables_weather)\n",
    "print(NDweather.head(20))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have some rows with NaN values. To deal with these let's drop the first 35 rows (since they contain a lot of NaN's). Note that since the data sets starts the same year, the same number of rows should be deleted from each of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    DATE  FZF0   PRCP  TAVG\n",
      "0   1954  27.0  22.83  41.3\n",
      "1   1955  28.0  20.47  39.4\n",
      "2   1956  30.0  19.78  39.6\n",
      "3   1957  28.0  16.99  40.5\n",
      "4   1958  27.0  11.83  41.2\n",
      "..   ...   ...    ...   ...\n",
      "64  2019  32.0  31.46  40.4\n",
      "65  2020  29.0  11.60  44.9\n",
      "66  2021  30.0  15.90  46.3\n",
      "67  2022  31.0  16.62  39.6\n",
      "68  2023   NaN    NaN   NaN\n",
      "\n",
      "[69 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "NDweather = NDweather.drop(index=range(35), axis=0)\n",
    "NDyield   = NDyield.drop(index=range(35), axis=0)\n",
    "NDweather.reset_index(inplace = True, drop = True)\n",
    "NDyield.reset_index(inplace = True, drop = True)\n",
    "print(NDweather.head(100))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the last row, 2023, also has NaN values, so it is dropped too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'drop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m NDweather \u001b[39m=\u001b[39m NDweather\u001b[39m.\u001b[39;49mdrop(NDweather\u001b[39m.\u001b[39mtail(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mindex, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m NDyield   \u001b[39m=\u001b[39m NDyield\u001b[39m.\u001b[39mdrop(NDyield(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mindex, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m NDweather\u001b[39m.\u001b[39mreset_index(inplace \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, drop \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'drop'"
     ]
    }
   ],
   "source": [
    "NDweather = NDweather.drop(NDweather.tail(1).index, inplace=True)\n",
    "NDyield   = NDyield.drop(NDyield(1).index, inplace=True)\n",
    "NDweather.reset_index(inplace = True, drop = True)\n",
    "NDyield.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore each data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to **explore the raw data**, you may provide **static** and **interactive plots** to show important developments "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interactive plot** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bec928ec179453498f01b6230f256ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Output(),), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_func():\n",
    "    # Function that operates on data set\n",
    "    pass\n",
    "\n",
    "widgets.interact(plot_func, \n",
    "    # Let the widget interact with data through plot_func()    \n",
    "); \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain what you see when moving elements of the interactive plot around. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you create combinations of your loaded data sets. Remember the illustration of a (inner) **merge**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'venn2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m15\u001b[39m,\u001b[39m7\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m v \u001b[39m=\u001b[39m venn2(subsets \u001b[39m=\u001b[39m (\u001b[39m4\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m10\u001b[39m), set_labels \u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mData X\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mData Y\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m      3\u001b[0m v\u001b[39m.\u001b[39mget_label_by_id(\u001b[39m'\u001b[39m\u001b[39m100\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mset_text(\u001b[39m'\u001b[39m\u001b[39mdropped\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m v\u001b[39m.\u001b[39mget_label_by_id(\u001b[39m'\u001b[39m\u001b[39m010\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mset_text(\u001b[39m'\u001b[39m\u001b[39mdropped\u001b[39m\u001b[39m'\u001b[39m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'venn2' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "v = venn2(subsets = (4, 4, 10), set_labels = ('Data X', 'Data Y'))\n",
    "v.get_label_by_id('100').set_text('dropped')\n",
    "v.get_label_by_id('010').set_text('dropped' )\n",
    "v.get_label_by_id('110').set_text('included')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are dropping elements from both data set X and data set Y. A left join would keep all observations in data X intact and subset only from Y. \n",
    "\n",
    "Make sure that your resulting data sets have the correct number of rows and columns. That is, be clear about which observations are thrown away. \n",
    "\n",
    "**Note:** Don't make Venn diagrams in your own data project. It is just for exposition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a quick overview of the data, we show some **summary statistics** on a meaningful aggregation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE FURTHER ANALYSIS. EXPLAIN THE CODE BRIEFLY AND SUMMARIZE THE RESULTS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADD CONCISE CONLUSION."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "47ef90cdf3004d3f859f1fb202523c65c07ba7c22eefd261b181f4744e2d0403"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
