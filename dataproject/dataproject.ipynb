{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOUR PROJECT TITLE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, I will be using two data sets that are relevant to agriculture and weather in the United States, specifically North Dakota, being one of the biggest wheat producing states in the US. The first data set contains information on yearly corn yield per acre, from around 1900 to 2022. This data is from USDA National Agricultural Statistics Service (NASS). The second data set contains yearly average temperature, precipitation, and the date of the first freeze, from a central weather station in North Dakota, with data ranging from a similar interval as the agricultural data. This data is sourced from the National Oceanic and Atmospheric Administration (NOAA). By combining these data sets, the hope is to investigate the relationship between weather patterns and corn production in the North Dakota over the past century."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and set magics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# autoreload modules when code is run\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# user written modules\n",
    "import dataproject\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and clean data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, let's read the first data set on wheat yield and inspect it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Program  Year               Period  Week Ending Geo Level         State  \\\n",
      "0  SURVEY  2022                 YEAR          NaN     STATE  NORTH DAKOTA   \n",
      "1  SURVEY  2021                 YEAR          NaN     STATE  NORTH DAKOTA   \n",
      "2  SURVEY  2020                 YEAR          NaN     STATE  NORTH DAKOTA   \n",
      "3  SURVEY  2019                 YEAR          NaN     STATE  NORTH DAKOTA   \n",
      "4  SURVEY  2018                 YEAR          NaN     STATE  NORTH DAKOTA   \n",
      "5  SURVEY  2017                 YEAR          NaN     STATE  NORTH DAKOTA   \n",
      "6  SURVEY  2016                 YEAR          NaN     STATE  NORTH DAKOTA   \n",
      "7  SURVEY  2015                 YEAR          NaN     STATE  NORTH DAKOTA   \n",
      "8  SURVEY  2015  YEAR - AUG FORECAST          NaN     STATE  NORTH DAKOTA   \n",
      "9  SURVEY  2015  YEAR - JUL FORECAST          NaN     STATE  NORTH DAKOTA   \n",
      "\n",
      "   State ANSI  Ag District  Ag District Code  County  ...  Zip Code  Region  \\\n",
      "0          38          NaN               NaN     NaN  ...       NaN     NaN   \n",
      "1          38          NaN               NaN     NaN  ...       NaN     NaN   \n",
      "2          38          NaN               NaN     NaN  ...       NaN     NaN   \n",
      "3          38          NaN               NaN     NaN  ...       NaN     NaN   \n",
      "4          38          NaN               NaN     NaN  ...       NaN     NaN   \n",
      "5          38          NaN               NaN     NaN  ...       NaN     NaN   \n",
      "6          38          NaN               NaN     NaN  ...       NaN     NaN   \n",
      "7          38          NaN               NaN     NaN  ...       NaN     NaN   \n",
      "8          38          NaN               NaN     NaN  ...       NaN     NaN   \n",
      "9          38          NaN               NaN     NaN  ...       NaN     NaN   \n",
      "\n",
      "   watershed_code  Watershed  Commodity                             Data Item  \\\n",
      "0               0        NaN      WHEAT  WHEAT - YIELD, MEASURED IN BU / ACRE   \n",
      "1               0        NaN      WHEAT  WHEAT - YIELD, MEASURED IN BU / ACRE   \n",
      "2               0        NaN      WHEAT  WHEAT - YIELD, MEASURED IN BU / ACRE   \n",
      "3               0        NaN      WHEAT  WHEAT - YIELD, MEASURED IN BU / ACRE   \n",
      "4               0        NaN      WHEAT  WHEAT - YIELD, MEASURED IN BU / ACRE   \n",
      "5               0        NaN      WHEAT  WHEAT - YIELD, MEASURED IN BU / ACRE   \n",
      "6               0        NaN      WHEAT  WHEAT - YIELD, MEASURED IN BU / ACRE   \n",
      "7               0        NaN      WHEAT  WHEAT - YIELD, MEASURED IN BU / ACRE   \n",
      "8               0        NaN      WHEAT  WHEAT - YIELD, MEASURED IN BU / ACRE   \n",
      "9               0        NaN      WHEAT  WHEAT - YIELD, MEASURED IN BU / ACRE   \n",
      "\n",
      "  Domain Domain Category Value  CV (%)  \n",
      "0  TOTAL   NOT SPECIFIED  48.9     NaN  \n",
      "1  TOTAL   NOT SPECIFIED  32.2     NaN  \n",
      "2  TOTAL   NOT SPECIFIED  47.6     NaN  \n",
      "3  TOTAL   NOT SPECIFIED  48.4     NaN  \n",
      "4  TOTAL   NOT SPECIFIED  47.6     NaN  \n",
      "5  TOTAL   NOT SPECIFIED  37.9     NaN  \n",
      "6  TOTAL   NOT SPECIFIED  45.0     NaN  \n",
      "7  TOTAL   NOT SPECIFIED  46.7     NaN  \n",
      "8  TOTAL   NOT SPECIFIED  46.4     NaN  \n",
      "9  TOTAL   NOT SPECIFIED  46.4     NaN  \n",
      "\n",
      "[10 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "NDyield = pd.read_csv('ND_yield.csv')\n",
    "\n",
    "print(NDyield.head(10))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, we have a lot of unnecessary information, that should be dropped for simplicity and to make the data set easier to manage. More importantly, the data also contains forecasts, and these are not needed, so should be deleted first: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = NDyield.Period.str.contains('FORECAST')\n",
    "NDyield = NDyield.loc[I == False] # keep everything else"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's make the data set narrower by dropping everything but the year and the average yield per acre (Most other variables have the same value in each row anyways, since all the data is from North Dakota)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Year  Value\n",
      "0   2022   48.9\n",
      "1   2021   32.2\n",
      "2   2020   47.6\n",
      "3   2019   48.4\n",
      "4   2018   47.6\n",
      "5   2017   37.9\n",
      "6   2016   45.0\n",
      "7   2015   46.7\n",
      "10  2014   46.3\n",
      "11  2013   45.4\n"
     ]
    }
   ],
   "source": [
    "drop_variables_yield = ['Program', 'Period', 'Week Ending','Geo Level','State','State ANSI','Ag District','Ag District Code', 'County', 'County ANSI', 'Zip Code', 'Region', 'watershed_code', 'Watershed','Commodity','Data Item', 'Domain', 'Domain Category', 'CV (%)']\n",
    "\n",
    "NDyield = NDyield.drop(columns = drop_variables_yield)\n",
    "\n",
    "print(NDyield.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are left with the information relevant to this project, let's continue by importing the weather data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       STATION                   NAME  DATE  FZF0  PRCP  TAVG\n",
      "0  USC00326365  NEW SALEM 5 NW, ND US  1923  30.0   NaN  40.9\n",
      "1  USC00326365  NEW SALEM 5 NW, ND US  1924   NaN   NaN   NaN\n",
      "2  USC00326365  NEW SALEM 5 NW, ND US  1925  27.0   NaN  43.0\n",
      "3  USC00326365  NEW SALEM 5 NW, ND US  1926  30.0   NaN   NaN\n",
      "4  USC00326365  NEW SALEM 5 NW, ND US  1927   NaN   NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "NDweather = pd.read_csv('ND_weather.csv')\n",
    "\n",
    "print(NDweather.head(5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we have some variables that can be dropped, namely 'NAME' and 'STATION', that are the same for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DATE  FZF0   PRCP  TAVG\n",
      "0  1923  30.0    NaN  40.9\n",
      "1  1924   NaN    NaN   NaN\n",
      "2  1925  27.0    NaN  43.0\n",
      "3  1926  30.0    NaN   NaN\n",
      "4  1927   NaN    NaN   NaN\n",
      "5  1928  30.0    NaN  43.2\n",
      "6  1929   NaN    NaN   NaN\n",
      "7  1931  28.0    NaN   NaN\n",
      "8  1932  32.0    NaN  41.4\n",
      "9  1933  30.0  12.86  42.5\n"
     ]
    }
   ],
   "source": [
    "drop_variables_weather = ['STATION', 'NAME']\n",
    "NDweather = NDweather.drop(columns=drop_variables_weather)\n",
    "print(NDweather.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There also seems to be a lot of missing values. To check for these, the .isna function can help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>FZF0</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TAVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1923</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1925</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1926</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1928</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1931</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1932</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1937</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1938</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1939</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1940</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1942</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1943</td>\n",
       "      <td>27.0</td>\n",
       "      <td>18.73</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1947</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1950</td>\n",
       "      <td>30.0</td>\n",
       "      <td>17.66</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1952</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DATE  FZF0   PRCP  TAVG\n",
       "0   1923  30.0    NaN  40.9\n",
       "1   1924   NaN    NaN   NaN\n",
       "2   1925  27.0    NaN  43.0\n",
       "3   1926  30.0    NaN   NaN\n",
       "4   1927   NaN    NaN   NaN\n",
       "5   1928  30.0    NaN  43.2\n",
       "6   1929   NaN    NaN   NaN\n",
       "7   1931  28.0    NaN   NaN\n",
       "8   1932  32.0    NaN  41.4\n",
       "13  1937  32.0    NaN  38.9\n",
       "14  1938  31.0    NaN  42.3\n",
       "15  1939  30.0    NaN  42.9\n",
       "16  1940  26.0    NaN  40.9\n",
       "18  1942  29.0    NaN  42.4\n",
       "19  1943  27.0  18.73   NaN\n",
       "23  1947  28.0    NaN  41.8\n",
       "24  1948   NaN    NaN   NaN\n",
       "26  1950  30.0  17.66   NaN\n",
       "28  1952  32.0   9.93   NaN\n",
       "32  1956   NaN  18.16   NaN\n",
       "99  2023   NaN    NaN   NaN"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NDweather[NDweather.isna().any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    DATE  FZF0   PRCP  TAVG\n",
      "0   2022  16.0  21.21  40.0\n",
      "1   2021  30.0  14.49  44.3\n",
      "2   2020  27.0  10.66  42.7\n",
      "3   2019  31.0  27.69  38.0\n",
      "4   2018  29.0  17.93  39.9\n",
      "..   ...   ...    ...   ...\n",
      "61  1961  30.0  13.44  42.3\n",
      "62  1960  30.0  14.92  41.8\n",
      "63  1959  22.0  10.95  41.0\n",
      "64  1958  32.0  10.57  42.4\n",
      "65  1957  30.0  19.73  41.6\n",
      "\n",
      "[66 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "NDweather = NDweather.iloc[98:32:-1].reset_index(drop=True)\n",
    "print(NDweather.head(100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>FZF0</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TAVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [DATE, FZF0, PRCP, TAVG]\n",
       "Index: []"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NDweather[NDweather.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    DATE  FZF0   PRCP  TAVG\n",
      "1   2021  30.0  14.49  44.3\n",
      "2   2020  27.0  10.66  42.7\n",
      "3   2019  31.0  27.69  38.0\n",
      "4   2018  29.0  17.93  39.9\n",
      "5   2017  30.0  12.50  41.7\n",
      "..   ...   ...    ...   ...\n",
      "61  1961  30.0  13.44  42.3\n",
      "62  1960  30.0  14.92  41.8\n",
      "63  1959  22.0  10.95  41.0\n",
      "64  1958  32.0  10.57  42.4\n",
      "65  1957  30.0  19.73  41.6\n",
      "\n",
      "[65 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "NDweather = NDweather.drop(index=range(1), axis=0)\n",
    "print(NDweather.head(100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have some rows with NaN values. To deal with these let's drop the first 35 rows (since they contain a lot of NaN's). Note that since the data sets starts the same year, the same number of rows should be deleted from each of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[0] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[324], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m NDweather \u001b[39m=\u001b[39m NDweather\u001b[39m.\u001b[39;49mdrop(index\u001b[39m=\u001b[39;49m\u001b[39mrange\u001b[39;49m(\u001b[39m35\u001b[39;49m), axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m NDyield   \u001b[39m=\u001b[39m NDyield\u001b[39m.\u001b[39mdrop(index\u001b[39m=\u001b[39m\u001b[39mrange\u001b[39m(\u001b[39m35\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m      3\u001b[0m NDweather\u001b[39m.\u001b[39mreset_index(inplace \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, drop \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\pandas\\core\\frame.py:5399\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5251\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   5252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   5253\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5260\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   5261\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5262\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5263\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5264\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5397\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5398\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5399\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   5400\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   5401\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5402\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   5403\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   5404\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   5405\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5406\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   5407\u001b[0m     )\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\pandas\\core\\generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4503\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4504\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4505\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4507\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4508\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\pandas\\core\\generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4544\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4545\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4546\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4547\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4549\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4550\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6934\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6932\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6933\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6934\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6935\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6936\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: '[0] not found in axis'"
     ]
    }
   ],
   "source": [
    "NDweather = NDweather.drop(index=range(35), axis=0)\n",
    "NDyield   = NDyield.drop(index=range(35), axis=0)\n",
    "NDweather.reset_index(inplace = True, drop = True)\n",
    "NDyield.reset_index(inplace = True, drop = True)\n",
    "print(NDweather.head(100))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the last row, 2023, also has NaN values, so it is dropped too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Year  Value\n",
      "0   1997   23.8\n",
      "1   1997   24.5\n",
      "2   1996   31.6\n",
      "3   1996   29.8\n",
      "4   1996   30.0\n",
      "..   ...    ...\n",
      "95  1971   31.8\n",
      "96  1971   30.8\n",
      "97  1971   29.3\n",
      "98  1971   31.5\n",
      "99  1970   23.6\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(NDyield.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'drop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m NDweather \u001b[39m=\u001b[39m NDweather\u001b[39m.\u001b[39;49mdrop(index\u001b[39m=\u001b[39mNDweather[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m      2\u001b[0m NDyield   \u001b[39m=\u001b[39m NDyield\u001b[39m.\u001b[39mdrop(NDyield(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mindex, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m NDweather\u001b[39m.\u001b[39mreset_index(inplace \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, drop \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'drop'"
     ]
    }
   ],
   "source": [
    "NDweather.drop(index=NDweather.index[-1],axis=0,inplace=True)\n",
    "NDyield.drop(index=NDyield.index[-1],axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore each data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to **explore the raw data**, you may provide **static** and **interactive plots** to show important developments "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interactive plot** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bec928ec179453498f01b6230f256ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Output(),), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_func():\n",
    "    # Function that operates on data set\n",
    "    pass\n",
    "\n",
    "widgets.interact(plot_func, \n",
    "    # Let the widget interact with data through plot_func()    \n",
    "); \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain what you see when moving elements of the interactive plot around. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you create combinations of your loaded data sets. Remember the illustration of a (inner) **merge**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'venn2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m15\u001b[39m,\u001b[39m7\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m v \u001b[39m=\u001b[39m venn2(subsets \u001b[39m=\u001b[39m (\u001b[39m4\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m10\u001b[39m), set_labels \u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mData X\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mData Y\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m      3\u001b[0m v\u001b[39m.\u001b[39mget_label_by_id(\u001b[39m'\u001b[39m\u001b[39m100\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mset_text(\u001b[39m'\u001b[39m\u001b[39mdropped\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m v\u001b[39m.\u001b[39mget_label_by_id(\u001b[39m'\u001b[39m\u001b[39m010\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mset_text(\u001b[39m'\u001b[39m\u001b[39mdropped\u001b[39m\u001b[39m'\u001b[39m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'venn2' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "v = venn2(subsets = (4, 4, 10), set_labels = ('Data X', 'Data Y'))\n",
    "v.get_label_by_id('100').set_text('dropped')\n",
    "v.get_label_by_id('010').set_text('dropped' )\n",
    "v.get_label_by_id('110').set_text('included')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are dropping elements from both data set X and data set Y. A left join would keep all observations in data X intact and subset only from Y. \n",
    "\n",
    "Make sure that your resulting data sets have the correct number of rows and columns. That is, be clear about which observations are thrown away. \n",
    "\n",
    "**Note:** Don't make Venn diagrams in your own data project. It is just for exposition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a quick overview of the data, we show some **summary statistics** on a meaningful aggregation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE FURTHER ANALYSIS. EXPLAIN THE CODE BRIEFLY AND SUMMARIZE THE RESULTS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADD CONCISE CONLUSION."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "47ef90cdf3004d3f859f1fb202523c65c07ba7c22eefd261b181f4744e2d0403"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
